# -*- coding: utf-8 -*-
"""session5 ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1onGifr1DlwJLeA4dnmDSWC078axUPqJ4
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score  , recall_score , precision_score , confusion_matrix , classification_report ,f1_score

"""#read data"""

data = pd.read_csv("/content/breast cancer.csv")
data.head()

data.columns

data.isnull().sum()

data.info()

data['diagnosis'].unique()

data['diagnosis'] = [1 if i == 'M' else 0 for i in data['diagnosis']]

data['diagnosis'].unique()

X = data.drop(["id" , "diagnosis" , "Unnamed: 32"] , axis = 1)
y = data['diagnosis']

X.head()

X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.33 , random_state = 42)

data.drop(columns=['id','Unnamed: 32'],inplace=True)

"""#build model"""

log_mode = LogisticRegression()

log_mode = log_mode.fit(X_train , y_train)

"""#predict"""

y_predict = log_mode.predict(X_test)
y_predict

"""#Evaluation

"""

#confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test , y_predict)

import seaborn as sns
sns.heatmap(cm , cmap ="Blues" , annot = True)

#classefication report
from sklearn.metrics import classification_report
print(classification_report(y_test,y_predict))

from sklearn.metrics import accuracy_score , recall_score , f1_score , precision_score
print("Accuracy score : " , accuracy_score(y_test , y_predict))
print("Recall score : " , recall_score(y_test , y_predict))
print("F1 score : " , f1_score(y_test , y_predict))
print("Precision score : " , precision_score(y_test , y_predict))

from sklearn.metrics import roc_curve
FPR ,TPR , threshold =roc_curve(y_test , y_predict)
plt.figure(figsize=(10,5))
plt.plot(FPR , TPR ,linewidth=2)
plt.plot([0,1],[0,1],"k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.show()

#AUC
from sklearn.metrics import roc_auc_score
roc_auc_score(y_test , y_predict)

